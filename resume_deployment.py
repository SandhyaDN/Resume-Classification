# -*- coding: utf-8 -*-
"""Resume-Deployment

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zvDlOSnTLnCeJSkN0DuzoP5jqN17m9k4
"""

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import joblib

# Placeholder for clean_text function
def clean_text(text):
    """
    This is a placeholder function for text cleaning.
    You might need to modify this function based on your specific needs.
    """
    if isinstance(text, str):
        return text.lower()  # Example: convert to lowercase
    return ""


df = pd.read_csv("resumes_dataset.csv")

x = df['text']
y = df['label']

# Train/Test split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Pipeline: TF-IDF + Logistic Regression
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features = None, preprocessor = clean_text)),
    ('logreg', LogisticRegression(random_state = 42, multi_class = 'multinomial'))
])
# creating new x, y for pipeline usage
x_pipe = df['text']
label_en = LabelEncoder()
y_pipe =  label_en.fit_transform(df['label'])
x_train_pipe, x_test_pipe, y_train_pipe, y_test_pipe = train_test_split(x_pipe, y_pipe, test_size = 0.2,
                                                                    random_state = 42, stratify = y_pipe)

# Fit pipeline
pipeline.fit(x_train_pipe, y_train_pipe)

# Save the pipeline
joblib.dump(pipeline, 'resume_pipeline.pkl')

# Streamlit App with pipe
import streamlit as st
import joblib
import docx2txt
import PyPDF2
import mammoth

# Load pipeline
pipeline = joblib.load("resume_pipeline.pkl")

# Function to extract text
def extract_text(file):
    text = ""
    if file.name.endswith(".docx"):
        text = docx2txt.process(file)
    elif file.name.endswith(".pdf"):
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text
    elif file.name.endswith(".doc"):
        result = mammoth.extract_raw_text(file)
        text = result.value
    return text

# Streamlit UI
st.title("ðŸ“„ Resume Classification App")

uploaded_file = st.file_uploader("Upload a resume (.doc, .docx, .pdf)", type=["doc", "docx", "pdf"])

if uploaded_file is not None:
    resume_text = extract_text(uploaded_file)

    if resume_text.strip():
        st.subheader("Extracted Resume Text")
        st.text_area("Text", resume_text[:1000] + "...", height=200)

        # Predict directly with pipeline
        prediction = pipeline.predict([resume_text])[0]

        st.subheader("Predicted Category")
        st.success(f"Predicted Category: {prediction}")
